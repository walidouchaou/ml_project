# SystÃ¨me d'Analyse et de PrÃ©diction pour le Trading de Crypto-monnaies

Ce projet est un systÃ¨me complet pour la collecte, le traitement, l'analyse et la prÃ©diction des donnÃ©es de trading de crypto-monnaies. Il utilise une architecture modulaire qui combine le stockage des donnÃ©es historiques, le traitement en temps rÃ©el, et la prÃ©diction Ã  l'aide de modÃ¨les de machine learning.

## ğŸ”‘ FonctionnalitÃ©s Principales

- **Chargement de donnÃ©es historiques** depuis MinIO vers DuckDB
- **Streaming en temps rÃ©el** des donnÃ©es de trading via Websocket Finnhub
- **Traitement et enrichissement des donnÃ©es** avec des indicateurs techniques
- **ModÃ¨les de prÃ©diction** basÃ©s sur Gradient Boosting
- **Visualisation interactive** des donnÃ©es et prÃ©dictions avec Streamlit
- **API** pour l'accÃ¨s aux donnÃ©es et aux prÃ©dictions

## Architecture du projet

![Architecture du projet](./src/img/Diagramme%20sans%20nom.drawio.png)

## ğŸ“‹ Structure du Projet

```          # Notebooks Jupyter pour l'analyse exploratoire
â”œâ”€â”€ src/                   # Code source
â”‚   â”œâ”€â”€ data/              # Module de gestion des donnÃ©es
â”‚   â”‚   â””â”€â”€ uplode_data.py # Script de chargement des donnÃ©es historiques
â”‚   â”œâ”€â”€ features/          # Extraction et traitement des caractÃ©ristiques
â”‚   â”‚   â”œâ”€â”€ data_processing.py      # Traitement des donnÃ©es
â”‚   â”‚   â””â”€â”€ data_processing_api.py  # API pour le traitement des donnÃ©es
â”‚   â”œâ”€â”€ models/            # ModÃ¨les de machine learning
â”‚   â”‚   â”œâ”€â”€ model_api/     # API pour accÃ©der aux modÃ¨les
â”‚   â”‚   â””â”€â”€ train_model/   # Scripts d'entraÃ®nement des modÃ¨les
â”‚   â”œâ”€â”€ visualization/     # Visualisation des donnÃ©es et rÃ©sultats
â”‚   â”‚   â””â”€â”€ app.py         # Application Streamlit pour la visualisation
â”‚   â””â”€â”€ websocket/         # Module de rÃ©cupÃ©ration de donnÃ©es en temps rÃ©el
â”‚       â””â”€â”€ finnhub_websocket.py # Client WebSocket pour Finnhub
â”œâ”€â”€ docker-compose.yml     # Configuration Docker pour MinIO
â”œâ”€â”€ requirements.txt       # DÃ©pendances Python
â””â”€â”€ .env                   # Configuration des variables d'environnement
```

## ğŸ› ï¸ PrÃ©requis

- Python 3.8+
- MinIO (pour le stockage des donnÃ©es)
- Compte Finnhub avec clÃ© API (pour les donnÃ©es en temps rÃ©el)

## ğŸ“¦ Installation

1. **Cloner le repository**
```bash
git clone <url-du-repository>
cd <nom-du-repository>
```

2. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

3. **Configurer l'environnement**
   - Copier `.env.example` vers `.env`
   - Remplir les variables d'environnement nÃ©cessaires

4. **DÃ©marrer MinIO avec Docker**
```bash
docker-compose up -d
```

## ğŸš€ Utilisation

### Chargement des donnÃ©es historiques

```python
from src.data.uplode_data import init_duckdb, process_file

# Initialiser la base de donnÃ©es
con = init_duckdb()

# Traiter un fichier CSV
process_file(con, "s3://btc/BTCUSDT-trades-2022-01.csv")
```

### Collecte des donnÃ©es en temps rÃ©el

```python
from src.websocket.finnhub_websocket import FinnhubWebSocket

# Initialiser et dÃ©marrer le WebSocket
ws = FinnhubWebSocket()
ws.start()  # Se connecte et commence Ã  collecter les donnÃ©es
```

### Traitement des donnÃ©es

```python
from src.features.data_processing import DataProcessing

# Initialiser le processeur de donnÃ©es
processor = DataProcessing()

# Traiter un DataFrame
df_processed = processor.process_data(df)
```

### Lancer l'application de visualisation

```bash
cd src/visualization
streamlit run app.py
```

## ğŸ§ª EntraÃ®nement des modÃ¨les

Le projet utilise principalement des modÃ¨les Gradient Boosting (GBR) pour la prÃ©diction. Pour entraÃ®ner un nouveau modÃ¨le:

1. AccÃ©der au notebook d'entraÃ®nement
```bash
jupyter notebook src/models/train_model/train_gbr_model.ipynb
```

2. Suivre les instructions dans le notebook pour:
   - Charger les donnÃ©es
   - PrÃ©parer les caractÃ©ristiques
   - Optimiser les hyperparamÃ¨tres
   - EntraÃ®ner le modÃ¨le
   - Ã‰valuer les performances
   - Sauvegarder le modÃ¨le

## âš™ï¸ Architecture Technique

### Stockage des donnÃ©es
- **MinIO**: Stockage des fichiers CSV bruts
- **DuckDB**: Base de donnÃ©es analytique pour le traitement rapide

### Traitement des donnÃ©es
- **Pandas**: Manipulation des donnÃ©es
- **Scikit-learn**: PrÃ©traitement et Ã©valuation des modÃ¨les

### ModÃ©lisation
- **XGBoost/LightGBM**: ModÃ¨les de prÃ©diction
- **Optuna**: Optimisation des hyperparamÃ¨tres

### Visualisation
- **Streamlit**: Interface utilisateur interactive
- **Plotly**: Graphiques dynamiques

## ğŸ”’ Configuration

Le fichier `.env` doit contenir les variables suivantes:

```
# Token Finnhub pour l'API
FINNHUB_TOKEN=votre_token_finnhub

# Configuration MinIO
MINIO_ENDPOINT=localhost:9000
MINIO_ACCESS_KEY=votre_access_key
MINIO_SECRET_KEY=votre_secret_key

# Configuration DuckDB
DUCKDB_MEMORY_LIMIT=15GB
DUCKDB_THREADS=8
DUCKDB_PATH=data/trades.duckdb
DUCKDB_TEMP_DIR=data/temp
```

## ğŸ¤ Contribution

Les contributions sont les bienvenues! N'hÃ©sitez pas Ã  ouvrir une issue ou une pull request.

## ğŸ“ Licence

Ce projet est sous licence [MIT](LICENSE). 